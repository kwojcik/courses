{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import kimports; reload(kimports); from kimports import *\n",
    "import kutils; reload(kutils)\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx = imdb.get_word_index()\n",
    "idx2word = {idx: word for word, idx in word2idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this data is all screwed up, the reviews dont make sense\n",
    "#(x_train, y_train), (x_test, y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(map(lambda x: idx2word[x], x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size=5000\n",
    "max_len=500\n",
    "num_factors = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = [np.array([i if i < vocab_size else vocab_size - 1 for i in review]) for review in x_train]\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=max_len)\n",
    "train_labels = labels_train\n",
    "valid_data = [np.array([i if i < vocab_size else vocab_size - 1 for i in review]) for review in x_test]\n",
    "valid_data = keras.preprocessing.sequence.pad_sequences(valid_data, maxlen=max_len)\n",
    "valid_labels = labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_input = keras.layers.Input(shape=(max_len,))\n",
    "review_embedding = keras.layers.embeddings.Embedding(vocab_size, num_factors, input_length=max_len, W_regularizer=keras.regularizers.l2(0.001))(review_input)\n",
    "flattened = keras.layers.core.Flatten()(review_embedding)\n",
    "dense = keras.layers.core.Dense(100, activation='relu')(flattened)\n",
    "dropout = keras.layers.core.Dropout(0.7)(dense)\n",
    "result = keras.layers.core.Dense(1, activation='sigmoid')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.Model(review_input, result)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 4s - loss: 0.4128 - acc: 0.8423 - val_loss: 0.3317 - val_acc: 0.8540\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 4s - loss: 0.3002 - acc: 0.9103 - val_loss: 0.3250 - val_acc: 0.8632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe947595d50>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          nb_epoch=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With some convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_input = keras.layers.Input(shape=(max_len,))\n",
    "review_embedding = keras.layers.embeddings.Embedding(vocab_size, num_factors, input_length=max_len, W_regularizer=keras.regularizers.l2(0.001))(review_input)\n",
    "conv1 = keras.layers.convolutional.Convolution1D(64, 5, activation='relu')(review_embedding)\n",
    "pooled = keras.layers.pooling.MaxPooling1D()(conv1)\n",
    "conv2 = keras.layers.convolutional.Convolution1D(64, 5, activation='relu')(pooled)\n",
    "flattened = keras.layers.core.Flatten()(conv2)\n",
    "dense = keras.layers.core.Dense(100, activation='relu')(flattened)\n",
    "dropout = keras.layers.core.Dropout(0.7)(dense)\n",
    "result = keras.layers.core.Dense(1, activation='sigmoid')(dropout)\n",
    "model = keras.models.Model(review_input, result)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 14s - loss: 0.4830 - acc: 0.7671 - val_loss: 0.2801 - val_acc: 0.8849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe928678a50>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          nb_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 14s - loss: 0.3221 - acc: 0.8982 - val_loss: 0.2562 - val_acc: 0.8918\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 14s - loss: 0.2960 - acc: 0.9100 - val_loss: 0.2541 - val_acc: 0.8942\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 14s - loss: 0.2675 - acc: 0.9237 - val_loss: 0.2602 - val_acc: 0.8920\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 14s - loss: 0.2532 - acc: 0.9328 - val_loss: 0.2696 - val_acc: 0.8938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe928678d50>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          nb_epoch=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_factors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_vectors = {}\n",
    "with open('../data/glove/glove.6B.50d.txt') as f:\n",
    "    for l in f:\n",
    "        tokens = l.split()\n",
    "        glove_vectors[tokens[0]] = np.array([map(float, tokens[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = np.zeros(((vocab_size, num_factors)))\n",
    "for idx in sorted(idx2word.keys())[:vocab_size-1]:\n",
    "    try:\n",
    "        emb[idx] = glove_vectors[idx2word[idx]]\n",
    "    except KeyError:\n",
    "        # word mismatch between glove and imdb words\n",
    "        emb[idx] = np.random.rand(num_factors)\n",
    "        \n",
    "# Set the \"everything else\" word to random\n",
    "emb[-1] = np.random.rand(num_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv model with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_input = keras.layers.Input(shape=(max_len,))\n",
    "review_embedding = keras.layers.embeddings.Embedding(vocab_size, num_factors, input_length=max_len, weights=[emb])(review_input)\n",
    "conv1 = keras.layers.convolutional.Convolution1D(64, 5, activation='relu')(review_embedding)\n",
    "pooled = keras.layers.pooling.MaxPooling1D()(conv1)\n",
    "conv2 = keras.layers.convolutional.Convolution1D(64, 5, activation='relu')(pooled)\n",
    "flattened = keras.layers.core.Flatten()(conv2)\n",
    "dense = keras.layers.core.Dense(100, activation='relu')(flattened)\n",
    "dropout = keras.layers.core.Dropout(0.7)(dense)\n",
    "result = keras.layers.core.Dense(1, activation='sigmoid')(dropout)\n",
    "model = keras.models.Model(review_input, result)\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 15s - loss: 0.6941 - acc: 0.5039 - val_loss: 0.6920 - val_acc: 0.5244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe907ff4310>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          nb_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 15s - loss: 0.5516 - acc: 0.7013 - val_loss: 0.3163 - val_acc: 0.8639\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 15s - loss: 0.2950 - acc: 0.8836 - val_loss: 0.2837 - val_acc: 0.8774\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 15s - loss: 0.2286 - acc: 0.9150 - val_loss: 0.2527 - val_acc: 0.8973\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 15s - loss: 0.1838 - acc: 0.9306 - val_loss: 0.2830 - val_acc: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe907ff4890>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels,\n",
    "          validation_data=(valid_data, valid_labels),\n",
    "          nb_epoch=4, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
